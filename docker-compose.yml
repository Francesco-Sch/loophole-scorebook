services:
  frontend:
    container_name: frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: production
    ports:
      - "3000:3000"
    networks:
      - app-network

  backend:
    container_name: backend
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: production
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_URL=${OLLAMA_URL}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL}
      - OLLAMA_EMBEDDING_URL=${OLLAMA_EMBEDDING_URL}
      - QDRANT_URL=${QDRANT_URL}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION}
    networks:
      - app-network

  vector-db:
    container_name: vector-db
    image: qdrant/qdrant:latest
    restart: always
    ports:
      - "6333:6333"
      # - "6334:6334" # Needed for grpc
    expose:
      - 6333
      # - 6334 # Needed for grpc
      # - 6335 # Needed for distributed mode
    configs:
      - source: qdrant_config
        target: /qdrant/config/production.yaml
    volumes:
      - ./database/data:/qdrant/storage:z
    networks:
      - app-network

  inference:
    container_name: inference
    build:
      context: ./inference
      dockerfile: Dockerfile
    volumes:
      - ./inference/data:/root/.ollama
    environment:
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_HOST=0.0.0.0:11000
    ports:
      - "11000:11000"
    networks:
      - app-network

  embeddings:
    container_name: embeddings
    build:
      context: ./embeddings
      dockerfile: Dockerfile
    volumes:
      - ./embeddings/data:/root/.ollama
    environment:
      - OLLAMA_MODEL=${OLLAMA_EMBEDDING_MODEL}
      - OLLAMA_HOST=0.0.0.0:11001
    ports:
      - "11001:11001"
    networks:
      - app-network

configs:
  qdrant_config:
    content: |
      log_level: INFO

networks:
  app-network:
    driver: bridge
